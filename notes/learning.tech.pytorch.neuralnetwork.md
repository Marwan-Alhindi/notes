---
id: 0p9o6amzwrbo7hmn1eleupk
title: Neuralnetwork
desc: ''
updated: 1745608072719
created: 1745603537272
---


- Whats the torch.nn module?
- How to build your model from nn.Module?
- Whats nn.Flatten() do?
- How can you create an instance of your model and then move it to the device?
- How to execute the model forward?
- How to get the logits and then get the pred probabilites using softmax?
- What are the general nn.Module features? PyTorchâ€™s nn.Module library includes core layers like Linear and Flatten, convolutional layers like Conv2d, pooling layers such as MaxPool2d, activation functions like ReLU and Softmax, normalization layers like BatchNorm2d, regularization tools such as Dropout, recurrent layers like LSTM, language-specific components like Embedding and Transformer, and loss functions like CrossEntropyLoss for training neural networks.
- Whats nn.ReLU and why you use it?
- Does everything inside torch.nn (like nn.Linear, nn.Conv2d, etc.) have __init__ and forward() methods under the hood?
- Whats nn.Softmax?
- How can you print the name and parameters size and parameters?