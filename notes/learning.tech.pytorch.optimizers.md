---
id: npver02f88gwo6de26zygty
title: Optimizers
desc: ''
updated: 1745662785081
created: 1745609528316
---

- Whats the cycle of training a model?
- What are hyperparameters? 
- What are epochs? Whats each epoch consits of two main parts?
- Whats learning rate?
- Whats a loss function? What are the commonloss functions for regression and classification?
- Give me examples of optimizers algorithms?
- How to initilize an optimizer and what do you have to pass to it?
- Why do you need to use optimizer.zero_grad() at each iteration of the training loop?
- How to adjust the parameters by the gradient collected from loss.backward()?
- what does optimizer.step() does?
